{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of questions:  1034\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
    "\n",
    "questions = \"datasets/spider_data/dev.json\"\n",
    "\n",
    "system_prompt = \"\"\"You are an expert SQL assistant specialized in converting natural language queries into accurate SQL statements. You:\n",
    "1. Understand database schemas and relationships\n",
    "2. Generate standard SQL queries that follow best practices\n",
    "3. Consider edge cases and data validation\n",
    "4. Can handle complex joins, aggregations, and nested queries\n",
    "5. Provide explanations for the generated SQL when needed\n",
    "\n",
    "When given a question, you will convert it to a valid SQL query based on the provided database schema.\"\"\"\n",
    "\n",
    "\n",
    "# Load questions from JSON file\n",
    "with open(questions, 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "print (\"total number of questions: \", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.spider import load_tables\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spider_table = 'tables.json'\n",
    "spider_dir = \"datasets/spider_data\"\n",
    "db = \"database\"\n",
    "\n",
    "dataset_dir = spider_dir\n",
    "table = spider_table\n",
    "\n",
    "# load schemas\n",
    "schemas, _ = load_tables([os.path.join(dataset_dir, table)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DB connections: 100%|██████████| 166/166 [00:02<00:00, 81.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#Backup in-memory copies of all the DBs and create the live connections\n",
    "for db_id, schema in tqdm(schemas.items(), desc=\"DB connections\"):\n",
    "    sqlite_path = Path(dataset_dir) / db / db_id / f\"{db_id}.sqlite\"\n",
    "    source: sqlite3.Connection\n",
    "    with sqlite3.connect(str(sqlite_path)) as source:\n",
    "        dest = sqlite3.connect(':memory:')\n",
    "        dest.row_factory = sqlite3.Row\n",
    "        source.backup(dest)\n",
    "    schema.connection = dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE Allergy_Type (\n",
      "       Allergy \t\t  VARCHAR(20) PRIMARY KEY,\n",
      "       AllergyType \t  VARCHAR(20)\n",
      ")\n",
      "CREATE TABLE Has_Allergy (\n",
      "       StuID \t\t INTEGER,\n",
      "       Allergy \t\t VARCHAR(20),\n",
      "       FOREIGN KEY(StuID) REFERENCES Student(StuID),\n",
      "       FOREIGN KEY(Allergy) REFERENCES Allergy_Type(Allergy)\n",
      ")\n",
      "CREATE TABLE Student (\n",
      "        StuID        INTEGER PRIMARY KEY,\n",
      "        LName        VARCHAR(12),\n",
      "        Fname        VARCHAR(12),\n",
      "        Age      INTEGER,\n",
      "        Sex      VARCHAR(1),\n",
      "        Major        INTEGER,\n",
      "        Advisor      INTEGER,\n",
      "        city_code    VARCHAR(3)\n",
      " )\n"
     ]
    }
   ],
   "source": [
    "db_id = \"allergy_1\"  # or any other db_id from your schemas\n",
    "connection = schemas[db_id].connection\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Query sqlite_master table to get all CREATE statements\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT sql \n",
    "    FROM sqlite_master \n",
    "    WHERE type='table' AND sql IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "# Print each CREATE statement\n",
    "for (sql,) in cursor.fetchall():\n",
    "    print(sql)\n",
    "    #print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sqlite3.Row at 0x209db3bf160>,\n",
       " <sqlite3.Row at 0x209db3bfac0>,\n",
       " <sqlite3.Row at 0x209db3bdd50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mingxuan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
